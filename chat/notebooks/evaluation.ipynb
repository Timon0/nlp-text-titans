{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c89f605-39c3-489a-a58d-603cbf5fd3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from model import Model\n",
    "\n",
    "torch.set_printoptions(linewidth=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16d9a-293a-4766-aec0-bb920eb1860b",
   "metadata": {},
   "source": [
    "# Load trained model\n",
    "Load the model from a trained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7011ff1-0dd9-4c14-88c5-e32d7410ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acbb54e-fffb-4c3b-8cd5-2c6896516a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): PeftModelForSeq2SeqLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): T5ForConditionalGeneration(\n",
       "        (shared): Embedding(32128, 768)\n",
       "        (encoder): T5Stack(\n",
       "          (embed_tokens): Embedding(32128, 768)\n",
       "          (block): ModuleList(\n",
       "            (0): T5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): T5LayerSelfAttention(\n",
       "                  (SelfAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (relative_attention_bias): Embedding(32, 12)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): T5LayerFF(\n",
       "                  (DenseReluDense): T5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1-11): 11 x T5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): T5LayerSelfAttention(\n",
       "                  (SelfAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): T5LayerFF(\n",
       "                  (DenseReluDense): T5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (final_layer_norm): T5LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (decoder): T5Stack(\n",
       "          (embed_tokens): Embedding(32128, 768)\n",
       "          (block): ModuleList(\n",
       "            (0): T5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): T5LayerSelfAttention(\n",
       "                  (SelfAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (relative_attention_bias): Embedding(32, 12)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): T5LayerCrossAttention(\n",
       "                  (EncDecAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (2): T5LayerFF(\n",
       "                  (DenseReluDense): T5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1-11): 11 x T5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): T5LayerSelfAttention(\n",
       "                  (SelfAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): T5LayerCrossAttention(\n",
       "                  (EncDecAttention): T5Attention(\n",
       "                    (q): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (v): Linear(\n",
       "                      in_features=768, out_features=768, bias=False\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (2): T5LayerFF(\n",
       "                  (DenseReluDense): T5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                    (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): T5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (final_layer_norm): T5LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model.load_from_checkpoint('flan-t5-base-batch4.ckpt')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base', truncation_side='left')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d0c48-35df-4aab-9cbb-92d217086574",
   "metadata": {},
   "source": [
    "# Configure dialog with model\n",
    "Creating an action to easily \"communicate\" with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f15943-c227-4fa0-afb6-f56821dfae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "\n",
    "def dialog(topic, prompt):\n",
    "    with torch.no_grad():\n",
    "        current_context = ''\n",
    "\n",
    "        if topic in context:\n",
    "            context[topic].append(prompt)\n",
    "        else:\n",
    "            context[topic] = []\n",
    "            context[topic].append(prompt)\n",
    "\n",
    "        current_context = ' '.join(context[topic])\n",
    "        tokenized_input = tokenizer(current_context, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        generated = model.model.generate(**tokenized_input, do_sample=True, top_p=0.9, max_new_tokens=200)\n",
    "        print(generated.dtype)\n",
    "        generated_text = tokenizer.decode(generated[0], skip_special_token=True)\n",
    "        context[topic].append(generated_text)\n",
    "\n",
    "        return generated_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1079fc56-9cad-439c-807a-e1efab13e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> I am open to suggestions and discussions, but I am afraid that I am not fully prepared for the potential impact that the White House might have on our own or other peoples. There are several factors that could affect the White House: 1. The White House is a political institution and has been founded on the principles of the US Constitution. The White House is a federal institution of government, and is governed by the Constitution and other laws. 2. The Senate is the administrative body of government and is run by the Senate and House of Representatives. This includes a broad range of constitutional laws and regulations, including the United States Constitution, the American Constitution, and the United States Constitution. 3. The Supreme Court is a court of law and is governed by the House of Representatives and House of Representatives. 4. The Supreme Court is a court of law and is ruled by the Senate and House of Representatives. 5. The House of Representatives is a federal institution and\n"
     ]
    }
   ],
   "source": [
    "print(dialog('eval', 'What is the white house?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63b18ca-83d0-43f2-88d6-5d329af4e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> It is governed by the American Constitution and other laws. The United States Constitution also grants access to certain regions of the United States that are part of the United States, including those located in countries that are members of the European Union or other third-country nations. Among the states that have a member state are: New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey: New Jersey, New Jersey:\n"
     ]
    }
   ],
   "source": [
    "print(dialog('eval', 'Who lives there?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bbffc1-c66c-4df4-ad62-8f20d6c1da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> The Python framework is used for writing and testing programs for Python. The framework has a modular approach, and the functions are built on top of each other, to allow the framework to be used in a wide range of applications. The framework allows users to define the Python programming framework using a graphical user interface (GUI), such as the Python script library and the Python interface, to make writing and testing program easier. The framework is also available as a plugin for Python, which allows users to create and use Python programs for their own programs, such as Python's GUI. The framework allows users to define the Python programming framework using the Python interface and the Python IDE, and has an application-specific interface for creating and deploying Python applications. This allows developers to easily create and deploy Python programs for use in Python's IDE, which are available on Python's website and on the Python programming framework. There is also a Java-based framework, which\n"
     ]
    }
   ],
   "source": [
    "print(dialog('python', 'What is python for?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd54644-4d00-4bd3-90e3-aa1f0852d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> I'm the driver in F1. It's my job to drive for the most advantage of my team, not for a paycheck. But I'm also responsible for managing our team, and supporting our drivers. I'm a team leader and I'm a team member. My job is to ensure I'm on the same level as other teams in F1. I can work with my team to ensure that they're in the same league and that they're able to get the support they need. I'm also responsible for managing my team's logistics and ensure that we keep track of important events and activities that need to be taken care of. I'm also responsible for managing my own team, and coordinating our own teamwork and resources. I'm responsible for managing my own team and supporting our own drivers, and I'm also responsible for managing the development and logistics of the team. I'm also responsible for keeping track\n"
     ]
    }
   ],
   "source": [
    "print(dialog('formel1', 'Who drives in F1?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d7175db-0481-4911-ba03-151a65eb4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> I have won the following titles: 1. The <unk>Atana<unk>a F1<unk> circuits. This game has been compared with F1. 3. The <unk>Italian<unk>a F1<unk> circuits. This game has been compared to F1. 4. The <unk>Asiatic<unk>a F1<unk> circuits. This game has been compared to F1. 5. The <unk>Italian<unk>a F1<unk> circuits. This game has been compared to F1. 6. The <unk>F1, and its many different teams have been compared. This game has been compared to F1. 7. The <unk>F1, and its many different teams have been compared to F1. 8. The <unk>F1, and its many different teams have been compared to F1. 9. The <unk>F1, and its many different teams have been compared to F1. 10. The <unk>F1<unk> circuits. This game has been\n"
     ]
    }
   ],
   "source": [
    "print(dialog('formel1', 'How many titles have you won?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0580be-da98-4efe-af6c-0fe81f5a029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> As of February 4, if the drivers are in Formula 1 with the team members currently at the track, they are still able to continue their racing on the track as part of a season of formula 1. However, the formula 1 events will be updated at a later date for you to get updated in case of changes. 4. In Formula 1: The formula 1 event will be featured on the team's website, and will be displayed in the aforementioned article. The afno, afno, and efno are all featured in Formula 1 games in season 3. In Formula 1, Formula 1 will also feature an updated Formula 1 show on July 5, which can be updated every day until June 25. 5. Formula 2: Formula 3 will feature a series of Formula 1 events in season 5. Formula 4 will feature a series of Formula 1 events in season 6. Formula 5 will feature a series of Formula 1 events in season 7. Formula 5\n"
     ]
    }
   ],
   "source": [
    "print(dialog('formel1', 'how many races are in one season of formula 1?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02597d5a-e394-4f27-9523-1fa560425d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> How to use Microsoft Word in a number of ways: 1. To make a new document from the beginning of the document, you can open the document and save it as a new document. 2. Open the document, select the new document and save the document as a new document. 3. Save the document and save the document as a new document. 4. Publish the new document. The new document will be created automatically if you save the new document. 5. Insert the new document into the document. 6. Convert the new document into a new document. 7. Save the new document and send it to your friends and family members. 8. Set your bookmarks and add the new document. 9. Edit the current document to your preferred format. 10. Close the new document and save the document. 11. Publish the new document with the new document. 12. Open the new document and delete the new document. 13. Close the new document and save the document. 14. Add the new document to\n"
     ]
    }
   ],
   "source": [
    "print(dialog('word', 'How can I use microsoft word?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c3807b-fc79-4ad2-a7ef-4aa94e011c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> Yes You can buy a copy of Microsoft Word or use it as a free edition. Here's an example of how you can buy Microsoft Word: 1. Download a copy of Microsoft Word: Download the app from the website of Microsoft Word: Click the \"Download\" button and follow the prompts to install the software. 2. Open the Microsoft Word document: Select the Microsoft Word document from the list of available languages and click \"Controll\". 3. Copy the Microsoft Word document. Note that the new document may require a few settings and other changes before being used. 4. Select a bookmark: Select the bookmark to save your new document. 5. Convert the new document into a new document. 6. Set your bookmarks and add the new document. 7. Set your bookmarks and add the new document. 8. Set your bookmarks and add the new document. 9. Edit the current document to your preferred format. 10. Close the new document and save the document. 11. Add the\n"
     ]
    }
   ],
   "source": [
    "print(dialog('word', 'Do I have to buy it to use it?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce95655-8722-4f9d-8f69-cf58de3d819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "<pad> I am currently trained as a professional software designer. I am currently not a qualified professional but I can help you with your certifications and background. 1. Download a copy of Microsoft Word: You can download the app from the website of Microsoft Word: Click the \"Download\" button and follow the prompts to install the software. 2. Open the Microsoft Word document: Select the Microsoft Word document from the list of available languages and click \"Controll\". 3. Copy the Microsoft Word document. Note that the new document may require a few settings and other changes before being used. 4. Set your bookmarks and add the new document. 5. Convert the new document into a new document. 6. Set your bookmarks and add the new document. 7. Set your bookmarks and add the new document. 8. Set your bookmarks and add the new document. 9. Edit the current document to your preferred format. 10. Close the new document and save the document. 11. Add the new document to Add\n"
     ]
    }
   ],
   "source": [
    "print(dialog('word', 'Where can I buy it?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2d28e-faf5-4df7-b21b-61bbf7296fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
